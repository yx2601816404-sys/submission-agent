# 任务契约

## 项目名称

投稿代理 MVP（Submission Agent）

## 目标

做到什么程度算完成：

把投稿代理做成一个可用的 MVP：用户输入作品信息（类型、主题、字数、风格等），系统匹配合适的竞赛，输出投稿建议（推荐竞赛列表 + 匹配理由 + 投稿注意事项）。最终交付一个端到端可运行的工具，至少 CLI 版本可用。

## 自主权范围

以下决定可以自己做，不需要请示：

- 技术选型（Python/Node/其他语言、框架）
- 数据结构设计（竞赛数据的存储格式、索引方式）
- 匹配算法的设计和迭代（关键词匹配、评分权重、排序逻辑）
- UI/UX 设计（CLI 交互方式、输出格式、颜色方案）
- 代码架构和模块划分
- 测试用例设计和自测方法
- competitions.json 的数据清洗和结构优化

## 必须请示的事项

以下事项必须先问过再做：

- 对外发布（发到 PyPI、GitHub public repo、或任何公开渠道）
- 收费模式的任何决定（免费/付费/freemium）
- 用户数据的处理方式（是否存储用户输入、是否做分析、隐私策略）
- 接入外部 API（如 LLM API）产生费用的决定
- 改变产品定位（从工具变成平台、从个人用变成 SaaS 等）

## 里程碑

做到以下节点时汇报一次：

1. **CLI 版可用** → 用户能通过命令行输入作品信息，拿到匹配结果。汇报：演示命令 + 示例输出
2. **匹配准确率自测** → 用至少 10 个测试用例验证匹配质量，给出准确率评估。汇报：测试报告 + 发现的问题
3. **完整 MVP** → 包含完整的输入→匹配→输出流程，错误处理，帮助文档。汇报：使用说明 + 最终演示

## 可用资源

工具、skill、API、其他 agent：

- `competitions.json`：85 条竞赛数据库（已有）
- `competitions-db-v2.md`：竞赛数据的结构化文档
- `matcher.py`：已有的匹配引擎代码
- `product-design.md`：产品设计文档
- `architecture-analysis.md`：架构分析文档
- `win-probability-framework.md`：获奖概率框架
- workspace 内的所有开发工具

## 时间预期

3 个里程碑预计 2-3 个工作周期完成。CLI 版应该最快，1 个周期内搞定。

## 质量标准

什么算"够好"：

- CLI 输入作品信息后 5 秒内返回结果
- 匹配结果至少返回 3 个推荐竞赛（如果数据库中有匹配的话）
- 每个推荐附带匹配理由（不是黑箱）
- 输入格式有明确提示，错误输入有友好报错
- 代码有基本注释，核心逻辑可读

## 备注

- 优先保证 CLI 版可用，Web UI 是后续的事
- 匹配算法不需要完美，但要能解释为什么推荐——可解释性比精度更重要
- 竞赛数据库会持续更新，数据结构要考虑扩展性
