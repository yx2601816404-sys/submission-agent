#!/usr/bin/env python3
"""
ç«èµ›æ•°æ®åº“å®æ—¶åˆ·æ–°æ¨¡å—
ä» pw.orgã€Reedsy ç­‰æºçˆ¬å–æœ€æ–°ç«èµ›ï¼Œåˆå¹¶åˆ° competitions.json
"""

import json
import re
import sys
import os
from datetime import datetime, date
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from html.parser import HTMLParser
from translator import auto_translate_name

DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "competitions.json")

# â”€â”€ é¢œè‰² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _c(text, code):
    if not sys.stdout.isatty():
        return text
    return f"\033[{code}m{text}\033[0m"

def _bold(t): return _c(t, "1")
def _green(t): return _c(t, "32")
def _yellow(t): return _c(t, "33")
def _red(t): return _c(t, "31")
def _dim(t): return _c(t, "2")


def fetch_url(url, timeout=15):
    """ç”¨ urllib æŠ“å–ç½‘é¡µå†…å®¹"""
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; SubmissionAgent/1.0)",
        "Accept": "text/html,application/xhtml+xml",
    }
    req = Request(url, headers=headers)
    try:
        with urlopen(req, timeout=timeout) as resp:
            return resp.read().decode("utf-8", errors="replace")
    except (URLError, HTTPError, TimeoutError) as e:
        print(f"  {_red('âœ—')} æŠ“å–å¤±è´¥: {url} â€” {e}")
        return None


def load_db():
    with open(DB_PATH, "r") as f:
        return json.load(f)


def save_db(data):
    with open(DB_PATH, "w") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def existing_names(data):
    names = set()
    for c in data["competitions"]:
        names.add(c["name"].lower().strip())
        if c.get("name_cn"):
            names.add(c["name_cn"].lower().strip())
    return names


def next_id(data):
    return max(c["id"] for c in data["competitions"]) + 1


def make_entry(id, name, name_cn, subfield, url, deadline, fee_amount, fee_currency,
               prize_details, prize_first=0, word_max=None, prestige=5, win_prob=5,
               fit_score=3, fit_advantages=None, fit_recommendation=""):
    """åˆ›å»ºæ ‡å‡†ç«èµ›æ¡ç›®"""
    return {
        "id": id,
        "name": name,
        "name_cn": name_cn,
        "field": "literature",
        "subfield": subfield,
        "url": url,
        "submission_url": url,
        "status": "open",
        "deadline": deadline,
        "result_date": None,
        "frequency": "annual",
        "entry_fee": {"amount": fee_amount, "currency": fee_currency},
        "prize": {"first": prize_first, "currency": fee_currency or "USD", "details": prize_details},
        "publication": None,
        "word_limit": {"min": None, "max": word_max, "unit": "words"} if word_max else None,
        "language": "en",
        "nationality_restriction": None,
        "age_restriction": None,
        "experience_restriction": None,
        "theme": None,
        "simultaneous_ok": None,
        "previously_published_ok": False,
        "anonymous_review": True,
        "ai_policy": None,
        "submission_method": "online",
        "submission_platform": "submittable",
        "judge": None,
        "prestige_score": prestige,
        "style_profile": {
            "style_tags": ["open", "literary"],
            "judge_preferences": None,
            "keywords": [],
            "past_winner_traits": None
        },
        "win_probability": {
            "competition_density": 5,
            "competitor_quality": 5,
            "estimated_submissions": None,
            "shortlist_rate": None,
            "overall_score": win_prob
        },
        "chinese_creator_fit": {
            "score": fit_score,
            "advantages": fit_advantages or [],
            "disadvantages": [],
            "recommendation": fit_recommendation
        }
    }


# â”€â”€ è§£æå™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def guess_subfield(text):
    """ä»æè¿°æ–‡æœ¬çŒœæµ‹ç«èµ›å­ç±»åˆ«"""
    t = text.lower()
    if "flash" in t:
        return "flash_fiction"
    if "poetry" in t or "poem" in t:
        return "poetry"
    if "novel" in t:
        return "novel"
    if "novella" in t:
        return "novella"
    if "screenplay" in t or "script" in t:
        return "screenplay"
    if "memoir" in t:
        return "memoir"
    if "nonfiction" in t or "non-fiction" in t or "essay" in t:
        return "nonfiction"
    if "short story" in t or "fiction" in t or "short fiction" in t:
        return "short_story"
    if "children" in t or "young adult" in t:
        return "children"
    return "multiple"


def parse_deadline_text(text):
    """è§£æå„ç§æ ¼å¼çš„æˆªæ­¢æ—¥æœŸæ–‡æœ¬"""
    if not text:
        return None
    text = text.strip()
    # æ ¼å¼: 2/28/26 æˆ– 02/28/26
    m = re.search(r'(\d{1,2})/(\d{1,2})/(\d{2,4})', text)
    if m:
        month, day, year = int(m.group(1)), int(m.group(2)), int(m.group(3))
        if year < 100:
            year += 2000
        try:
            return f"{year}-{month:02d}-{day:02d}"
        except ValueError:
            pass
    # æ ¼å¼: March 31, 2026
    m = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2}),?\s*(\d{4})', text, re.I)
    if m:
        months = {"january":1,"february":2,"march":3,"april":4,"may":5,"june":6,
                  "july":7,"august":8,"september":9,"october":10,"november":11,"december":12}
        month = months.get(m.group(1).lower(), 1)
        day = int(m.group(2))
        year = int(m.group(3))
        return f"{year}-{month:02d}-{day:02d}"
    # æ ¼å¼: 2026-03-31
    m = re.search(r'(\d{4})-(\d{2})-(\d{2})', text)
    if m:
        return m.group(0)
    return None


def parse_fee(text):
    """ä»æ–‡æœ¬ä¸­æå–è´¹ç”¨"""
    if not text:
        return 0, "USD"
    text = text.strip()
    if text == "$0" or "free" in text.lower() or text == "0":
        return 0, "USD"
    m = re.search(r'\$(\d+)', text)
    if m:
        return int(m.group(1)), "USD"
    m = re.search(r'[â‚¬Â£](\d+)', text)
    if m:
        amount = int(m.group(1))
        currency = "EUR" if "â‚¬" in text else "GBP"
        return amount, currency
    m = re.search(r'(\d+)', text)
    if m:
        return int(m.group(1)), "USD"
    return 0, "USD"


def parse_prize(text):
    """ä»æ–‡æœ¬ä¸­æå–å¥–é‡‘é‡‘é¢"""
    if not text:
        return 0, ""
    m = re.search(r'\$(\d[\d,]*)', text)
    if m:
        return int(m.group(1).replace(",", "")), text.strip()
    m = re.search(r'[â‚¬Â£](\d[\d,]*)', text)
    if m:
        return int(m.group(1).replace(",", "")), text.strip()
    return 0, text.strip()


# â”€â”€ pw.org çˆ¬å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def crawl_pworg():
    """ä» Poets & Writers (pw.org) çˆ¬å–ç«èµ›åˆ—è¡¨"""
    print(f"\n{_bold('ğŸ” çˆ¬å– pw.org ...')}")
    results = []

    html = fetch_url("https://www.pw.org/grants")
    if not html:
        return results

    # pw.org HTML ç»“æ„:
    # <a href="/writing_contests/xxx" class="title">Name</a>
    # <span class="views-label-field-cash-prize">Cash Prize: </span><span class="field-content">$X</span>
    # <span class="views-label-field-entry-amount-int">Entry Fee: </span><span class="field-content">$X</span>
    # <span class="views-label-field-deadline">Application Deadline: </span><span class="field-content">M/D/YY</span>

    # æŒ‰ç«èµ›å—åˆ†å‰²
    blocks = re.split(r'<a href="/writing_contests/', html)

    for block in blocks[1:]:
        try:
            # åç§°
            name_m = re.search(r'class="title">([^<]+)</a>', block)
            if not name_m:
                continue
            name = name_m.group(1).strip()

            # URL
            slug_m = re.match(r'([^"]+)"', block)
            url = f"https://www.pw.org/writing_contests/{slug_m.group(1)}" if slug_m else ""

            # Cash Prize
            prize_m = re.search(r'Cash Prize:.*?field-content">\$?([\d,]+)', block, re.S)
            prize_amount = int(prize_m.group(1).replace(",", "")) if prize_m else 0

            # Entry Fee
            fee_m = re.search(r'Entry Fee:.*?field-content">\$?([\d,]+)', block, re.S)
            fee = int(fee_m.group(1).replace(",", "")) if fee_m else 0

            # Deadline
            dl_m = re.search(r'Deadline:.*?field-content">([^<]+)', block, re.S)
            deadline = parse_deadline_text(dl_m.group(1)) if dl_m else None

            # æè¿°
            desc_m = re.search(r'<p>([^<]{10,300})', block)
            desc = desc_m.group(1).strip() if desc_m else name

            subfield = guess_subfield(name + " " + desc)

            results.append({
                "name": name,
                "url": url,
                "prize_first": prize_amount,
                "prize_details": f"${prize_amount:,}" if prize_amount else "",
                "fee_amount": fee,
                "fee_currency": "USD",
                "deadline": deadline,
                "subfield": subfield,
                "description": desc[:200],
            })
        except Exception:
            continue

    print(f"  {_green('âœ“')} è§£æåˆ° {len(results)} ä¸ªç«èµ›")
    return results


# â”€â”€ Reedsy çˆ¬å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def crawl_reedsy():
    """ä» Reedsy çˆ¬å–ç«èµ›åˆ—è¡¨"""
    print(f"\n{_bold('ğŸ” çˆ¬å– Reedsy ...')}")
    results = []

    html = fetch_url("https://reedsy.com/resources/writing-contests/")
    if not html:
        return results

    # Reedsy HTML ç»“æ„:
    # <h3><a href="URL">Name</a></h3>
    # <b>Top Prize:</b> ... $X
    # Entry fee: ... $X
    # Deadline: ... Date

    # æŒ‰ç«èµ›å—åˆ†å‰² â€” æ¯ä¸ª <h3> å¼€å§‹ä¸€ä¸ªæ–°ç«èµ›
    blocks = re.split(r'<h3[^>]*>\s*<a', html)

    for block in blocks[1:]:
        try:
            # åç§°å’ŒURL
            name_m = re.search(r'href="([^"]*)"[^>]*>([^<]+)</a>', block)
            if not name_m:
                continue
            url = name_m.group(1).replace("&amp;", "&")
            name = name_m.group(2).strip()

            # è·³è¿‡ Expired
            if "(Expired)" in block or "Expired" in block[:500]:
                continue

            # Top Prize
            prize_m = re.search(r'Top Prize:.*?[\$Â£â‚¬]([\d,]+)', block, re.S)
            prize_amount = int(prize_m.group(1).replace(",", "")) if prize_m else 0

            # Entry fee
            fee_m = re.search(r'Entry fee.*?[\$Â£â‚¬](\d+)', block, re.S)
            if not fee_m:
                # Check for $0 or free
                if re.search(r'Entry fee.*?\$0', block, re.S):
                    fee = 0
                else:
                    fee = 0
            else:
                fee = int(fee_m.group(1))

            # Deadline
            dl_m = re.search(r'Deadline:.*?</[^>]+>\s*([^<]+)', block, re.S)
            deadline_text = dl_m.group(1).strip() if dl_m else ""
            deadline = parse_deadline_text(deadline_text)

            # Genres
            genre_m = re.search(r'Genres:.*?</[^>]+>\s*([^<]+)', block, re.S)
            genres = genre_m.group(1).strip() if genre_m else ""
            subfield = guess_subfield(name + " " + genres)

            results.append({
                "name": name,
                "url": url,
                "prize_first": prize_amount,
                "prize_details": f"${prize_amount:,}" if prize_amount else "",
                "fee_amount": fee,
                "fee_currency": "USD",
                "deadline": deadline,
                "subfield": subfield,
                "description": genres,
            })
        except Exception:
            continue

    print(f"  {_green('âœ“')} è§£æåˆ° {len(results)} ä¸ªç«èµ›")
    return results


# â”€â”€ NewPages çˆ¬å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def crawl_newpages():
    """ä» NewPages Big List of Writing Contests çˆ¬å–"""
    print(f"\n{_bold('ğŸ” çˆ¬å– NewPages ...')}")
    results = []

    html = fetch_url("https://www.newpages.com/guide-submission-opportunities/big-list-of-writing-contests/")
    if not html:
        return results

    # NewPages ç»“æ„: æ¯ä¸ªç«èµ›åœ¨ <p> æ ‡ç­¾å†…
    # <p><a href="URL">Publisher</a><br />Contest Name<br />Genre<br />Fee info<br />Deadline</p>
    year = date.today().year

    # æå–æ‰€æœ‰ <p> å—ä¸­åŒ…å«å¤–éƒ¨é“¾æ¥çš„æ¡ç›®
    pattern = re.compile(
        r'<p[^>]*>'
        r'\s*(?:<strong>)?'
        r'<a[^>]*href="(https?://(?!www\.newpages)[^"]+)"[^>]*>([^<]+)</a>'
        r'\s*<br\s*/?>\s*'
        r'([^<]+?)<br\s*/?>\s*'   # contest name
        r'([^<]+?)<br\s*/?>\s*'   # genre
        r'([^<]*?)'               # fee info
        r'(?:<br\s*/?>)?\s*'
        r'(?:(?:Opens\s+\d{2}/\d{2}\s*\|\s*)?Closes\s+)?'
        r'(\d{2}/\d{2})',         # deadline MM/DD
        re.S
    )

    for m in pattern.finditer(html):
        try:
            url = m.group(1).strip()
            publisher = m.group(2).strip()
            contest_name = m.group(3).strip()
            genre = m.group(4).strip()
            fee_info = m.group(5).strip()
            deadline_mmdd = m.group(6).strip()

            # æ¸…ç† HTML å®ä½“
            contest_name = contest_name.replace("&#8217;", "'").replace("&amp;", "&").replace("&#8211;", "â€“")
            publisher = publisher.replace("&#8217;", "'").replace("&amp;", "&")

            # è·³è¿‡å¤ªçŸ­çš„åå­—
            if len(contest_name) < 3:
                continue

            name = contest_name

            # è§£ææˆªæ­¢æ—¥æœŸ (MM/DD -> YYYY-MM-DD)
            month, day = deadline_mmdd.split("/")
            month, day = int(month), int(day)
            deadline_date = date(year, month, day)
            if deadline_date < date.today():
                deadline_date = date(year + 1, month, day)
            deadline = str(deadline_date)

            # è§£æè´¹ç”¨
            is_free = "free" in fee_info.lower()
            fee_amount = 0 if is_free else 0  # é‡‘é¢æœªçŸ¥æ—¶è®¾ä¸º0

            subfield = guess_subfield(contest_name + " " + genre)

            results.append({
                "name": name,
                "url": url,
                "prize_first": 0,
                "prize_details": "",
                "fee_amount": fee_amount,
                "fee_currency": "USD",
                "deadline": deadline,
                "subfield": subfield,
                "description": f"{genre} | {publisher}",
            })
        except Exception:
            continue

    print(f"  {_green('âœ“')} è§£æåˆ° {len(results)} ä¸ªç«èµ›")
    return results


# â”€â”€ åˆå¹¶é€»è¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def merge_results(crawled, data, dry_run=False, max_add=50):
    """å°†çˆ¬å–ç»“æœåˆå¹¶åˆ°æ•°æ®åº“ï¼Œè¿”å›æ–°å¢æ•°é‡"""
    names = existing_names(data)
    nid = next_id(data)
    added = 0
    today = date.today()
    # åªæ¥å—æœªæ¥6ä¸ªæœˆå†…æˆªæ­¢çš„ç«èµ›
    from datetime import timedelta
    cutoff = today + timedelta(days=180)

    for item in crawled:
        if added >= max_add:
            break

        name = item["name"]
        if name.lower().strip() in names:
            continue

        # è·³è¿‡å·²è¿‡æœŸ
        dl = item.get("deadline")
        if dl:
            try:
                dl_date = datetime.strptime(dl, "%Y-%m-%d").date()
                if dl_date < today:
                    continue
                if dl_date > cutoff:
                    continue  # å¤ªè¿œçš„ä¹Ÿè·³è¿‡
            except ValueError:
                pass

        # è·³è¿‡æœ‰å›½ç±é™åˆ¶çš„ï¼ˆä»æè¿°æ¨æ–­ï¼‰
        desc = item.get("description", "").lower()
        restricted = any(kw in desc for kw in [
            "resident of", "residents of", "citizen of", "citizens of",
            "african american", "african descent", "legal resident",
            "living in the", "who reside in"
        ])
        if restricted:
            print(f"  {_dim('è·³è¿‡')} {name} {_dim('(å¯èƒ½æœ‰åœ°åŸŸé™åˆ¶)')}")
            continue

        if dry_run:
            print(f"  {_yellow('+')} {name} | {item.get('deadline', '?')} | ${item.get('fee_amount', 0)} | ${item.get('prize_first', 0)}")
        else:
            comp = make_entry(
                id=nid, name=name, name_cn=auto_translate_name(name),
                subfield=item.get("subfield", "multiple"),
                url=item.get("url", ""),
                deadline=item.get("deadline"),
                fee_amount=item.get("fee_amount", 0),
                fee_currency=item.get("fee_currency", "USD"),
                prize_details=item.get("prize_details", ""),
                prize_first=item.get("prize_first", 0),
                prestige=5, win_prob=5, fit_score=3,
            )
            data["competitions"].append(comp)
            print(f"  {_green('+')} #{nid} {name}")
            nid += 1

        names.add(name.lower().strip())
        added += 1

    return added


# â”€â”€ ä¸»å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def refresh(dry_run=False, sources=None):
    """æ‰§è¡Œæ•°æ®åº“åˆ·æ–°"""
    print(f"\n{_bold('ğŸ”„ ç«èµ›æ•°æ®åº“å®æ—¶åˆ·æ–°')}")
    print(f"{_dim(f'æ—¥æœŸ: {date.today()}')}")

    data = load_db()
    before = len(data["competitions"])

    all_crawled = []

    available_sources = {
        "pworg": ("pw.org (Poets & Writers)", crawl_pworg),
        "reedsy": ("Reedsy", crawl_reedsy),
        "newpages": ("NewPages", crawl_newpages),
    }

    if sources:
        to_crawl = {k: v for k, v in available_sources.items() if k in sources}
    else:
        to_crawl = available_sources

    for key, (label, func) in to_crawl.items():
        try:
            results = func()
            all_crawled.extend(results)
        except Exception as e:
            print(f"  {_red('âœ—')} {label} çˆ¬å–å‡ºé”™: {e}")

    if not all_crawled:
        print(f"\n{_yellow('æ²¡æœ‰çˆ¬å–åˆ°æ–°æ•°æ®ã€‚')}")
        return 0

    print(f"\n{_bold('ğŸ“‹ åˆå¹¶ç»“æœ:')}")
    added = merge_results(all_crawled, data, dry_run=dry_run)

    if not dry_run and added > 0:
        data["updated"] = str(date.today())
        save_db(data)

    after = len(data["competitions"]) if not dry_run else before + added
    print(f"\n{_bold('ğŸ“Š åˆ·æ–°å®Œæˆ:')}")
    print(f"  çˆ¬å–åˆ°: {len(all_crawled)} æ¡")
    print(f"  æ–°å¢: {_green(str(added))} æ¡ {'(é¢„è§ˆæ¨¡å¼)' if dry_run else ''}")
    print(f"  æ•°æ®åº“: {before} â†’ {after} æ¡")

    return added


if __name__ == "__main__":
    dry = "--dry-run" in sys.argv
    refresh(dry_run=dry)
